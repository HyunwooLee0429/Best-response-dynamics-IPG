{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfedaaff-afe1-4c99-8942-bd0d52613254",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data handling, optimization, and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random, time, copy\n",
    "import pickle\n",
    "from itertools import permutations\n",
    "from gurobipy import *\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab7f106-c4c0-4fdd-8408-ffdfe1193516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your working directory\n",
    "my_folder = \"C:/Users/hyunwoolee/OneDrive - Virginia Tech/Hyunwoo Research\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a503f0c-d4c2-4aa2-93e8-fd982b3c3794",
   "metadata": {},
   "source": [
    "## General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435715b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_x_to_obj(selected_items):\n",
    "    \"\"\"\n",
    "    Converts a given strategy profile (selected_items) into\n",
    "    binary decision variables and computes both individual (selfish)\n",
    "    and global objective values.\n",
    "\n",
    "    Parameters:\n",
    "        selected_items (dict): Dictionary mapping each player to their selected items.\n",
    "\n",
    "    Returns:\n",
    "        selfish_obj (dict): Objective value for each individual player.\n",
    "        global_obj (float): Total objective value across all players.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize binary decision variables x[player][item]\n",
    "    x = {}\n",
    "    for player in players:\n",
    "        x[player] = {\n",
    "            i: 1 if i in selected_items[player] else 0\n",
    "            for i in items\n",
    "        }\n",
    "\n",
    "    # Compute individual (selfish) objective for each player\n",
    "    selfish_obj = {}\n",
    "    for player in players:\n",
    "        # Direct profit + interaction-based profit\n",
    "        selfish_obj[player] = sum(profits[player][i] * x[player][i] for i in items) + sum(interactions[action][i] * x[action[0]][i] * x[action[1]][i]\n",
    "                for i in items for action in players_interaction if action[0] == player)\n",
    "\n",
    "    # Compute global objective as the sum of all players' objectives\n",
    "    global_obj = sum(selfish_obj[player] for player in players)\n",
    "\n",
    "    return selfish_obj, global_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0946c-97bf-4799-84e5-e9d4a24e088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSolution(model,x, selected_items):    \n",
    "    \n",
    "    # Check if the model found a feasible solution\n",
    "    if model.SolCount > 0:\n",
    "        print('\\nObjvalue: %g' % model.ObjVal)\n",
    "        for player in players:\n",
    "            for i in items:\n",
    "                if x[player][i].X > 0.1:\n",
    "                    #print('item %d for player %d: %g' % (i, player, x[player][i].X))\n",
    "                    selected_items[player].append(i)\n",
    "    else:\n",
    "        pass # No feasible solution found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d001e7",
   "metadata": {},
   "source": [
    "## Cycle_diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d059da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cycle_Diagnostic(selected_items):\n",
    "    # Initialize flag for cycle detection\n",
    "    Cycle_found = False\n",
    "    S = []\n",
    "    \n",
    "    # Check for duplicate lake entries (indicates a cycle)\n",
    "    for i in range(len(selected_items)):\n",
    "        if selected_items[i] in S:\n",
    "            # print('\\n Cycle detected =================================================================================\\n')\n",
    "            Cycle_found = True\n",
    "            return Cycle_found\n",
    "        S.append(selected_items[i])\n",
    "            \n",
    "    return Cycle_found            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a30352-974f-423b-b8fb-9a3c31b50db7",
   "metadata": {},
   "source": [
    "## Social Welfare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc103f7-87b8-4587-a14e-ad7ad2cdc4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function builds and solves a Gurobi model that maximizes social welfare\n",
    "\n",
    "def SW_model(time_limit, usage):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Gurobi Model\n",
    "    model = Model(\"SW model\")\n",
    "    \n",
    "    # Decision variables\n",
    "    x={}\n",
    "    for player in players:\n",
    "        x[player] = {}\n",
    "        for i in items:\n",
    "            x[player][i] = model.addVar(vtype = GRB.BINARY,name=\"x_[%s][%s]\"%(str(player),str(i)))\n",
    " \n",
    "    y={}\n",
    "    for action in players_interaction:\n",
    "        y[action] = {}\n",
    "        for i in items:\n",
    "            y[action][i] = model.addVar(vtype = GRB.BINARY,name=\"y_[%s][%s]\"%(str(action),str(i)))\n",
    "            \n",
    "    # Player-level knapsack constraints\n",
    "    for player in players:\n",
    "        model.addConstr( quicksum(weights[player][i]*x[player][i] for i in items)  <= budgets[player])\n",
    "        \n",
    "    # Logical constraints for interaction variables y[action][i]\n",
    "    for action in players_interaction:\n",
    "        for i in items:\n",
    "            model.addConstr(y[action][i] <= x[action[0]][i])\n",
    "            model.addConstr(y[action][i] <= x[action[1]][i])\n",
    "            model.addConstr(y[action][i] >= x[action[0]][i]+x[action[1]][i]-1)\n",
    "    \n",
    "    # === Objective function: maximize total social welfare ===\n",
    "    model.setObjective(quicksum(profits[player][i]*x[player][i] for i in items for player in players) \n",
    "                       + quicksum(interactions[action][i]*y[action][i] for i in items for action in players_interaction)\n",
    "                       ,GRB.MAXIMIZE)\n",
    "\n",
    "    # Set time limit based on usage type\n",
    "    if usage == 'OSW':\n",
    "        model.setParam('TimeLimit',time_limit)\n",
    "    elif usage == 'OSW_warm':\n",
    "        model.setParam('TimeLimit',time_limit/6)\n",
    "\n",
    "    # Solver parameters    \n",
    "    model.Params.LogToConsole = 0\n",
    "    model.Params.Threads =  user_Threads\n",
    "\n",
    "    # Solve the model\n",
    "    model.optimize()\n",
    "    runtime=model.Runtime\n",
    "    \n",
    "    # Extract selected items from solution\n",
    "    selected_items = {player: [] for player in players}\n",
    "    printSolution(model,x, selected_items)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    return model, elapsed_time, selected_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2b146-8c71-43d2-b420-e7d405f555a9",
   "metadata": {},
   "source": [
    "## Best-response problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7fb8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function defines the best-response problem for a single player (player_fixed)\n",
    "### Given other players' strategies, it solves the player's own knapsack problem.\n",
    "\n",
    "def selfish_KP(player_fixed):\n",
    "    # Initialize a Gurobi model for the player's selfish optimization\n",
    "    model = Model(\"KP\")\n",
    "    model.Params.LogToConsole = 0\n",
    "    model.Params.Threads = user_Threads\n",
    "\n",
    "    # Decision variables: x[player][item] for all players (only player_fixed will be free)\n",
    "    x = {\n",
    "        player: {\n",
    "            i: model.addVar(vtype=GRB.BINARY, name=f\"x_[{player}][{i}]\")\n",
    "            for i in items\n",
    "        }\n",
    "        for player in players\n",
    "    }\n",
    "\n",
    "    # Knapsack constraint for the selected player\n",
    "    model.addConstr(\n",
    "        quicksum(weights[player_fixed][i] * x[player_fixed][i] for i in items) <= budgets[player_fixed]\n",
    "    )\n",
    "\n",
    "    # Objective: maximize the player's utility (direct + pairwise interaction terms)\n",
    "    model.setObjective(\n",
    "        quicksum(profits[player_fixed][i] * x[player_fixed][i] for i in items) +\n",
    "        quicksum(interactions[action][i] * x[action[0]][i] * x[action[1]][i]\n",
    "                 for action in players_interaction if action[0] == player_fixed\n",
    "                 for i in items),\n",
    "        GRB.MAXIMIZE\n",
    "    )\n",
    "\n",
    "    model.update()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfef081",
   "metadata": {},
   "source": [
    "## CR-BRD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e8c7e7-39b5-49a1-9a24-2442837a1e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feasible_solution(budgets, items, weights):\n",
    "    \"\"\"\n",
    "    Generates a feasible knapsack solution ensuring high budget utilization with randomness.\n",
    "\n",
    "    Args:\n",
    "        budgets (dict): Available budget for each player.\n",
    "        items (list): List of all available items.\n",
    "        weights (dict): Dictionary of item weights per player.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where each player is assigned a feasible set of selected items.\n",
    "    \"\"\"\n",
    "    x_current = {}\n",
    "\n",
    "    for player in players:\n",
    "        selected_items = set()\n",
    "        remaining_budget = budgets[player]\n",
    "\n",
    "        # Step 1: Shuffle items to introduce randomness\n",
    "        shuffled_items = items[:]\n",
    "        random.shuffle(shuffled_items)\n",
    "\n",
    "        # Step 2: Iteratively add items while staying within the budget\n",
    "        for item in shuffled_items:\n",
    "            if weights[player][item] <= remaining_budget:\n",
    "                selected_items.add(item)\n",
    "                remaining_budget -= weights[player][item]\n",
    "\n",
    "        x_current[player] = list(selected_items)  # Convert set to list\n",
    "\n",
    "    return x_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1342995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BRD(x_current, selfish_model, max_init, max_iteration):\n",
    "    \"\"\"\n",
    "    Executes the Clockwork-Random Best-Response Dynamics (CR-BRD) algorithm for the KPG game.\n",
    "\n",
    "    Starting from an initial strategy profile, this function iteratively updates each player's strategy\n",
    "    using best-response optimization. If cycles are detected, randomization is introduced into the\n",
    "    playing sequence to escape local loops. The algorithm searches for a Pure Nash Equilibrium (PNE).\n",
    "\n",
    "    Args:\n",
    "        x_current (dict): Initial strategy profile; mapping from player to list of selected items.\n",
    "        selfish_model (dict or None): Dictionary of pre-built Gurobi models for each player's\n",
    "                                      best-response problem. If None, models will be built on demand.\n",
    "        max_init (int): Maximum number of randomized initial profiles to explore.\n",
    "        max_iteration (int): Maximum number of BRD updates per initialization.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            selected_items_final (dict): Final strategy profile (player → selected items).\n",
    "            BR_PNE_found (bool): True if a Pure Nash Equilibrium was found.\n",
    "            Cycle_found (bool): True if a cycle was detected during any run.\n",
    "            total_iterations (int): Total number of best-response updates performed.\n",
    "            solution (dict): Final utility values for each player under the final profile.\n",
    "    \"\"\"\n",
    "    \n",
    "    global BR_PNE_found, I_c\n",
    "\n",
    "    # Initialize selected_items and solution dictionary\n",
    "    selected_items = {}\n",
    "    selected_items[0] = {}\n",
    "    for player in players:\n",
    "        selected_items[0][player] = [i for i in x_current[player]]        \n",
    "    solution = {}\n",
    "    solution[0] = from_x_to_obj(x_current)[0]\n",
    "\n",
    "    # Create a container for selfish models if not already provided\n",
    "    if selfish_model == None:\n",
    "        selfish_model = {}\n",
    "\n",
    "    # Initial settings\n",
    "    playing_sequence = players\n",
    "    randomized, Cycle_found = False, False\n",
    "    total_iterations = 0\n",
    "    \n",
    "    # Try up to max_init different initial strategy profiles\n",
    "    for num_init in range(1,max_init+1):\n",
    "        if num_init > 1:\n",
    "            ## Generate any strategy profile\n",
    "            x_current = generate_feasible_solution(budgets, items, weights)\n",
    "            \n",
    "            # Reset initial selections and utilities            \n",
    "            selected_items = {}\n",
    "            selected_items[0] = {}\n",
    "            for player in players:\n",
    "                selected_items[0][player] = [i for i in x_current[player]]        \n",
    "            solution = {}\n",
    "            solution[0] = from_x_to_obj(x_current)[0]\n",
    "        \n",
    "        # Run best-response updates up to max_iteration times\n",
    "        for num in range(1,max_iteration+1):\n",
    "            total_iterations += 1\n",
    "\n",
    "            selected_items[num] = {}\n",
    "            solution[num] = {}\n",
    "            for player in players:\n",
    "                solution[num][player] = 0\n",
    "                selected_items[num][player] = selected_items[num-1][player]\n",
    "\n",
    "            for player in playing_sequence:\n",
    "                # Reuse or initialize best-response model for this player\n",
    "                if player not in selfish_model:\n",
    "                    selfish_model[player] = selfish_KP(player)\n",
    "\n",
    "                # Fixed decisions from other players are used to set values\n",
    "                for p in players_complement[player]:\n",
    "                    selected_items_previous = [item for item in selected_items[num][p]]\n",
    "                    for item in items:                     \n",
    "                        var = selfish_model[player].getVarByName(f\"x_[{p}][{item}]\")\n",
    "                        if item in selected_items_previous:                \n",
    "                            var.lb, var.ub = 1, 1\n",
    "                        else:\n",
    "                            var.lb, var.ub = 0, 0\n",
    "                            \n",
    "                # Warm-starting with the current strategy profile\n",
    "                selected_items_previous = [item for item in selected_items[num][player]]\n",
    "                selfish_model[player].getVarByName(f\"x_[{player}][{item}]\").start = 1 if item in selected_items_previous else 0\n",
    "\n",
    "                selfish_model[player].update()\n",
    "                selfish_model[player].optimize()\n",
    "                \n",
    "                # Store best-response outcome\n",
    "                solution[num][player] = selfish_model[player].ObjVal\n",
    "                selected_items[num][player] = [item for item in items if selfish_model[player].getVarByName(f\"x_[{player}][{item}]\").X > 0.1]\n",
    "                                    \n",
    "            # Check for convergence to a Pure Nash Equilibrium\n",
    "            if selected_items[len(selected_items)-1] == selected_items[len(selected_items)-2]:\n",
    "                # print(' PNE found at %d iteration ================================================================== '%(num))\n",
    "                BR_PNE_found = True\n",
    "                selected_items_final = selected_items[num]\n",
    "\n",
    "                return selected_items_final, BR_PNE_found, Cycle_found, total_iterations, solution[num]  \n",
    "        \n",
    "            # Enable random play order if a cycle is detected\n",
    "            if randomized:\n",
    "                players_tmp = players.copy()\n",
    "                random.shuffle(players_tmp)\n",
    "                playing_sequence = players_tmp\n",
    "            else:\n",
    "                Cycle_found = Cycle_Diagnostic(selected_items) \n",
    "                if Cycle_found:                    \n",
    "                    randomized = True\n",
    "                    players_tmp = players.copy()\n",
    "                    random.shuffle(players_tmp)\n",
    "                    playing_sequence = players_tmp\n",
    "\n",
    "    # No equilibrium found after all initializations and iterations        \n",
    "    return {player: [] for player in players}, False, True, total_iterations, {player:0 for player in players}     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a6cf13-24b8-44ab-9042-7269b50ef19a",
   "metadata": {},
   "source": [
    "## Strategic Inequalities for KPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd353ad2-1bb0-44f7-a0d5-b674b1f83faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"\"\"\n",
    "    Generates all subsets (power set) of a given iterable.\n",
    "    Args:\n",
    "        iterable (iterable): Input elements.\n",
    "    Returns:\n",
    "        generator: All possible subsets of the input.\n",
    "    \"\"\"\n",
    "    \n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb85444-7035-4561-8466-84ffedcd9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimal_subsets_indices_with_negative_sum(scalar, value_list):\n",
    "    \"\"\"\n",
    "    Finds the first subset (with smallest size) of value_list such that \n",
    "    the adjusted sum (scalar + sum(subset)) is negative.\n",
    "\n",
    "    The function terminates as soon as it finds the first subset (in enumeration order)\n",
    "    that satisfies this condition and is shorter than any previous one.\n",
    "\n",
    "    Args:\n",
    "        scalar (float): Baseline value to start the sum.\n",
    "        value_list (list of float): List of values to choose from.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Indices of the first minimal subset whose adjusted sum is negative.\n",
    "               Returns None if no such subset exists.\n",
    "    \"\"\"\n",
    "    min_indices = None\n",
    "    min_sum = float('inf')\n",
    "    min_len = float('inf')\n",
    "\n",
    "    for indices in powerset(range(len(value_list))):\n",
    "        subset_sum = scalar + sum(value_list[i] for i in indices)\n",
    "        if subset_sum < 0 and len(indices) < min_len:\n",
    "            min_sum = subset_sum\n",
    "            min_len = len(indices)\n",
    "            min_indices = indices\n",
    "            # Early exit if smallest possible subset (empty) has negative sum\n",
    "            if min_len == 0:\n",
    "                break\n",
    "\n",
    "    return min_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c9abb6-e3e1-4af1-a03c-ffacb4d4ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategic_calculation(category):\n",
    "    \"\"\"\n",
    "    Computes strategic inequalities for the KPG model, including:\n",
    "    - Strategic Dominance Inequalities: If one item strictly dominates another.\n",
    "    - Strategic Payoff Inequalities: To avoid negative profie based on the other player's choices.\n",
    "\n",
    "    Args:\n",
    "        category (str): Type of interaction (e.g., 'C' for negative interactions).\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            dominance_relationships (list): List of (player, item_dominant, item_dominated) tuples.\n",
    "            strategic_payoff_relationships (list): List of [player, item, subset_indices, subset_size].\n",
    "    \"\"\"\n",
    "\n",
    "    # === Strategic Dominance Inequality Computation ===\n",
    "    profit_interactions = {player: {} for player in players}\n",
    "    profit_max = {player: {} for player in players}\n",
    "    profit_min = {player: {} for player in players}\n",
    "    items_pair = list(permutations(items, 2))\n",
    "\n",
    "    for player in players:\n",
    "        for item in items:\n",
    "            # Interaction terms where the player is the first actor\n",
    "            profit_interactions[player][item] = [\n",
    "                interactions[action][item] for action in players_interaction if action[0] == player\n",
    "            ]\n",
    "\n",
    "            # Compute all possible sums with and without interaction\n",
    "            min_val, max_val = float('inf'), float('-inf')\n",
    "            for subset in powerset(profit_interactions[player][item]):\n",
    "                total = profits[player][item] + sum(subset)\n",
    "                min_val = min(min_val, total)\n",
    "                max_val = max(max_val, total)\n",
    "\n",
    "            profit_min[player][item] = min_val\n",
    "            profit_max[player][item] = max_val\n",
    "\n",
    "    # Identify item dominance relationships\n",
    "    dominance_relationships = []\n",
    "    for player in players:\n",
    "        for i1, i2 in items_pair:\n",
    "            if profit_min[player][i1] > profit_max[player][i2]:\n",
    "                if weights[player][i1] <= weights[player][i2]:\n",
    "                    dominance_relationships.append((player, i1, i2))\n",
    "\n",
    "    # === Strategic Payoff Inequality Computation ===\n",
    "    strategic_payoff_relationships = []\n",
    "\n",
    "    if category == 'C':\n",
    "        for player in players:\n",
    "            for item in items:\n",
    "                minimal_subset = minimal_subsets_indices_with_negative_sum(\n",
    "                    profits[player][item], profit_interactions[player][item]\n",
    "                )\n",
    "\n",
    "                if minimal_subset:\n",
    "                    strategic_payoff_relationships.append(\n",
    "                        [player, item, list(minimal_subset), len(minimal_subset)]\n",
    "                    )\n",
    "\n",
    "        # Adjust interaction indices to match original interaction structure\n",
    "        for str_payoff in strategic_payoff_relationships:\n",
    "            pivot = str_payoff[0]\n",
    "            for i in range(len(str_payoff[2])):\n",
    "                if pivot <= str_payoff[2][i]:\n",
    "                    str_payoff[2][i] += 1\n",
    "\n",
    "    return dominance_relationships, strategic_payoff_relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d8aa0-e1a3-4e16-95f1-ee4af475c165",
   "metadata": {},
   "source": [
    "## Separation Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This callback function integrates a separation oracle to enforce equilibrium inequalities\n",
    "\n",
    "def Separation(model, where):\n",
    "    global x, y, EI_cuts, selfish_model, first_PNE_obj, first_time, start_time, PNE_sets\n",
    "\n",
    "    violated = False\n",
    "\n",
    "    # Trigger only when a new feasible integer solution is found\n",
    "    if where == GRB.Callback.MIPSOL:\n",
    "        # Extract current incumbent solution\n",
    "        x_current = {player: [] for player in players}\n",
    "        for player in players:\n",
    "            x_current[player] = [i for i in items if model.cbGetSolution(x[player][i]) > 0.3 ]\n",
    "        curr_selfish_obj, curr_global_obj = from_x_to_obj(x_current) \n",
    "        \n",
    "        for player in players:\n",
    "            # Reuse or create a selfish model for this county\n",
    "            if player not in selfish_model:\n",
    "                selfish_model[player] = selfish_KP(player)\n",
    "                \n",
    "            # Fix other counties’ decisions in the model\n",
    "            for p in players_complement[player]:\n",
    "                for item in items:                     \n",
    "                    var = selfish_model[player].getVarByName(f\"x_[{p}][{item}]\")\n",
    "                    if item in x_current[p]:                \n",
    "                        var.lb, var.ub = 1, 1\n",
    "                    else:\n",
    "                        var.lb, var.ub = 0, 0\n",
    "                        \n",
    "            # Warm-starting with the current strategy profile\n",
    "            for item in items:\n",
    "                selfish_model[player].getVarByName(f\"x_[{player}][{item}]\").start = 1 if item in x_current[player] else 0\n",
    "                    \n",
    "            # Solve the player’s best-response problem\n",
    "            selfish_model[player].optimize()\n",
    "            \n",
    "            # If a better response exists, add a lazy cut to eliminate the deviation\n",
    "            if selfish_model[player].ObjVal > curr_selfish_obj[player]:\n",
    "                best_response_items = [item for item in items if selfish_model[player].getVarByName(f\"x_[{player}][{item}]\").X > 0.3]\n",
    "                # print(f'Best utility: {selfish_model[player].ObjVal}')\n",
    "                # print(f'Current utility: {curr_selfish_obj[player]}')                \n",
    "                # print('Best utility is higher than current utility')\n",
    "                # print(\"\\n\"+\"=\"*35 + \"  Call Lazy cuts  \" + \"=\"*35)\n",
    "                \n",
    "                # Add equilibrium inequality (lazy cut)\n",
    "                model.cbLazy(\n",
    "                    sum(profits[player][i]*1 for i in items if i in best_response_items)\n",
    "                    +quicksum(interactions[action][i]*1*x[action[1]][i] for i in items for action in players_interaction if (action[0]==player) and (i in best_response_items))\n",
    "                    <= quicksum(profits[player][i]*x[player][i] for i in items) \n",
    "                   + quicksum(interactions[action][i]*y[action][i] for i in items for action in players_interaction if action[0]==player)\n",
    "                )\n",
    "                EI_cuts.append(1)\n",
    "                violated = True\n",
    "\n",
    "            # print(\"\\n\"+\"=\"*35 + \"  Continue Main program  \" + \"=\"*35)\n",
    "            # print(\"    Nodes    |    Current Node    |     Objective Bounds      |     Work\") \n",
    "            # print(\" Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\")\n",
    "\n",
    "        # Record the first PNE (Pure Nash Equilibrium) and its discovery time\n",
    "        if violated == False and first_PNE_obj == None:\n",
    "            first_PNE_obj = curr_global_obj \n",
    "            first_time = time.time() - start_time\n",
    "\n",
    "        # Store the new PNE if it's unique\n",
    "        if (violated == False) and (x_current not in PNE_sets):\n",
    "            PNE_sets.append(x_current)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1307e14-5963-47d9-9b98-e3ea5004253c",
   "metadata": {},
   "source": [
    "## CR-BRD Incorporated Separation Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b15dc-dd0b-4a93-9362-666438e26323",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This callback function integrates both a separation oracle and the CR-BRD algorithm\n",
    "\n",
    "def BRD_Separation(model, where):\n",
    "    global x, y, EI_cuts, PNE_cuts, selfish_model, first_PNE_obj, first_time, start_time, best_obj, BR_sets, PNE_sets\n",
    "\n",
    "    violated = False\n",
    "\n",
    "    # Trigger only when a new feasible integer solution is found\n",
    "    if where == GRB.Callback.MIPSOL:\n",
    "        # Extract the current solution (selected lakes)\n",
    "        x_current = {player: [] for player in players}\n",
    "        for player in players:\n",
    "            x_current[player] = [i for i in items if model.cbGetSolution(x[player][i]) > 0.3 ]            \n",
    "        curr_selfish_obj, curr_global_obj = from_x_to_obj(x_current)    \n",
    "        \n",
    "        for player in players:\n",
    "            # Reuse or initialize selfish model for the county\n",
    "            if player not in selfish_model:\n",
    "                selfish_model[player] = selfish_KP(player)\n",
    "                \n",
    "            # Fix other counties’ decisions in the model\n",
    "            for p in players_complement[player]:\n",
    "                for item in items:                     \n",
    "                    var = selfish_model[player].getVarByName(f\"x_[{p}][{item}]\")\n",
    "                    if item in x_current[p]:                \n",
    "                        var.lb, var.ub = 1, 1\n",
    "                    else:\n",
    "                        var.lb, var.ub = 0, 0\n",
    "\n",
    "            # Warm-starting with the current strategy profile\n",
    "            for item in items:\n",
    "                selfish_model[player].getVarByName(f\"x_[{player}][{item}]\").start = 1 if item in x_current[player] else 0\n",
    "                    \n",
    "            # Solve the player's best-response problem\n",
    "            selfish_model[player].optimize()\n",
    "            \n",
    "            # If a better response exists, add a lazy cut to eliminate the deviation\n",
    "            if selfish_model[player].ObjVal > curr_selfish_obj[player]:\n",
    "                best_response_items = [item for item in items if selfish_model[player].getVarByName(f\"x_[{player}][{item}]\").X > 0.3]\n",
    "                # print(f'Best utility: {selfish_model[player].ObjVal}')\n",
    "                # print(f'Current utility: {curr_selfish_obj[player]}')                \n",
    "                # print('Best utility is higher than current utility')\n",
    "                # print(\"\\n\"+\"=\"*35 + \"  Call Lazy cuts  \" + \"=\"*35)\n",
    "                \n",
    "                # Add equilibrium inequality (lazy cut)\n",
    "                model.cbLazy(\n",
    "                    sum(profits[player][i]*1 for i in items if i in best_response_items)\n",
    "                    +quicksum(interactions[action][i]*1*x[action[1]][i] for i in items for action in players_interaction if (action[0]==player) and (i in best_response_items))\n",
    "                    <= quicksum(profits[player][i]*x[player][i] for i in items) \n",
    "                   + quicksum(interactions[action][i]*y[action][i] for i in items for action in players_interaction if action[0]==player)\n",
    "                )\n",
    "                EI_cuts.append(1)\n",
    "                violated = True\n",
    "                \n",
    "        # Record the first PNE (Pure Nash Equilibrium) and its discovery time\n",
    "        if violated == False and first_PNE_obj == None:\n",
    "            first_PNE_obj = curr_global_obj \n",
    "            first_time = time.time() - start_time\n",
    "            \n",
    "        # print(\"\\n\"+\"=\"*35 + \"  Continue Main program  \" + \"=\"*35)\n",
    "        # print(\"    Nodes    |    Current Node    |     Objective Bounds      |     Work\") \n",
    "        # print(\" Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\")\n",
    "\n",
    "        # Apply CR-BRD if the current solution is a non-PNE\n",
    "        if violated == False:\n",
    "            BRD_items, BR_PNE_found, current_sol = x_current, True, curr_selfish_obj\n",
    "        else:        \n",
    "            BRD_items, BR_PNE_found, Cycle_found, total_iterations, current_sol  = BRD(x_current, selfish_model, max_init=5, max_iteration=20)\n",
    "        \n",
    "        # If a new PNE is found through separation or CR-BRD\n",
    "        if (BR_PNE_found == True) and (BRD_items not in PNE_sets):\n",
    "            curr_global_obj = sum(current_sol[player] for player in players)\n",
    "            for player in players:\n",
    "                \n",
    "                # If this best response for a county hasn't been found before, add a PNE inequality\n",
    "                if BRD_items[player] not in BR_sets[player]:\n",
    "                    # Add PNE inequality (lazy cut)\n",
    "                    model.cbLazy(\n",
    "                        sum(profits[player][i]*1 for i in items if i in BRD_items[player])\n",
    "                        +quicksum(interactions[action][i]*1*x[action[1]][i] for i in items for action in players_interaction if (action[0]==player) and (i in BRD_items[player]))\n",
    "                        <= quicksum(profits[player][i]*x[player][i] for i in items) \n",
    "                       + quicksum(interactions[action][i]*y[action][i] for i in items for action in players_interaction if action[0]==player)\n",
    "                    )\n",
    "                    PNE_cuts.append(1)\n",
    "                    BR_sets[player].append(BRD_items[player])\n",
    "                \n",
    "            # Update primal solution if this PNE improves the global objective\n",
    "            if curr_global_obj > best_obj:\n",
    "                best_obj = curr_global_obj\n",
    "                for player in players:\n",
    "                    for i in BRD_items[player]:            \n",
    "                        model.cbSetSolution(x[player][i], 1)\n",
    "    \n",
    "            # Track this new PNE\n",
    "            PNE_sets.append(BRD_items)\n",
    "            \n",
    "            # Store the new PNE if it's unique\n",
    "            if first_PNE_obj == None:\n",
    "                first_PNE_obj = curr_global_obj \n",
    "                first_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec8ea9a-2162-4c8e-a4e0-48e39c757f98",
   "metadata": {},
   "source": [
    "## ZR and BZR algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ed24ca-a0f9-4a8b-b4db-84231aac5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZR(time_limit, warm_start_PNE, category, callback_type):\n",
    "    \"\"\"\n",
    "    Zero-Regret (ZR) algorithm solver for the KPG game using Gurobi.\n",
    "\n",
    "    This function adds equilibrium inequalities through callback-based separation or CR-BRD augmentation.\n",
    "    Optionally includes strategic dominance and payoff inequalities for smaller instances.\n",
    "\n",
    "    Args:\n",
    "        time_limit (float): Time budget for solving the MIP model (in seconds).\n",
    "        warm_start_PNE (bool): Not used in current logic, but can enable warm-starting in the future.\n",
    "        category (str): Indicates interaction type; used for conditional cut generation (e.g., 'A', 'B', or 'C').\n",
    "        callback_type (str): \n",
    "            - 'Separation' applies basic equilibrium inequalities (ZR).\n",
    "            - 'BRD_Separation' adds CR-BRD enhanced equilibrium cuts (BZR).\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            model (gurobipy.Model): Solved Gurobi model instance.\n",
    "            elapsed_time (float): Total wall-clock time to solve.\n",
    "            best_response_items (dict): Selected items per player from final solution.\n",
    "            first_PNE_obj (float): Objective value of the first identified PNE, if any.\n",
    "            first_time (float): Wall-clock time when the first PNE was discovered.\n",
    "            cuts_summary (list): [#EI_basic, #EI_dominance, #EI_payoff, #PNE_cuts].\n",
    "            PNE_sets (list): List of all identified Pure Nash Equilibria.\n",
    "    \"\"\"\n",
    "    \n",
    "    global x, y, EI_cuts, PNE_cuts, selfish_model, first_PNE_obj, first_time, start_time, best_obj, BR_sets, PNE_sets\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Initialize storage for cuts, models, and tracking info\n",
    "    EI_P_cuts, EI_D_cuts, EI_cuts, PNE_cuts = [], [], [], []\n",
    "    BR_sets = {player: [] for player in players}\n",
    "    first_PNE_obj, first_time, best_obj = None, None, -10000\n",
    "\n",
    "    \n",
    "    # Strategic inequalities are used only for small instances (n <= 15)\n",
    "    if len(players) <= 15:\n",
    "        dominance_relationships, strategic_payoff_relationships = strategic_calculation(category)\n",
    "    selfish_model = {}\n",
    "    PNE_sets = []\n",
    "\n",
    "    # Build Gurobi model\n",
    "    model = Model(f\"ZR_model\")\n",
    "\n",
    "    # Decision variables\n",
    "    x={}\n",
    "    for player in players:\n",
    "        x[player] = {}\n",
    "        for i in items:\n",
    "            x[player][i] = model.addVar(vtype = GRB.BINARY,name=\"x_var_[%s][%s]\"%(str(player),str(i)))\n",
    "\n",
    "    y={}\n",
    "    for action in players_interaction:\n",
    "        y[action] = {}\n",
    "        for i in items:\n",
    "            y[action][i] = model.addVar(vtype = GRB.BINARY,name=\"y_var_[%s][%s]\"%(str(player),str(i)))\n",
    "\n",
    "    # Player-level knapsack constraints\n",
    "    for player in players:\n",
    "        model.addConstr( quicksum(weights[player][i]*x[player][i] for i in items)  <= budgets[player])\n",
    "\n",
    "    # Logical constraints for interaction variables y[action][i]  \n",
    "    for action in players_interaction:\n",
    "        for i in items:\n",
    "            model.addConstr(y[action][i] <= x[action[0]][i])\n",
    "            model.addConstr(y[action][i] <= x[action[1]][i])\n",
    "            model.addConstr(y[action][i] >= x[action[0]][i]+x[action[1]][i]-1)\n",
    "\n",
    "    # === Add strategic inequalities for small-scale games ===\n",
    "    if len(players) <= 15:\n",
    "        # Strategic Dominance Inequalities\n",
    "        for player, i1, i2 in dominance_relationships:\n",
    "            model.addConstr(x[player][i2] <= x[player][i1])\n",
    "            EI_D_cuts.append((player, i1, i2))\n",
    "                \n",
    "        # Strategic Payoff Inequalities\n",
    "        for str_pay in strategic_payoff_relationships: \n",
    "            model.addConstr( x[str_pay[0]][str_pay[1]] + quicksum(x[other_player][str_pay[1]] for other_player in str_pay[2]) <= str_pay[3])\n",
    "            EI_P_cuts.append(str_pay)    \n",
    "            \n",
    "    # === Objective: Maximize social welfare (individual + pairwise interaction) ===\n",
    "    model.setObjective(quicksum(profits[player][i]*x[player][i] for i in items for player in players) \n",
    "                       + quicksum(interactions[action][i]*y[action][i] for i in items for action in players_interaction)\n",
    "                       ,GRB.MAXIMIZE)\n",
    "\n",
    "    # === Gurobi solver settings ===\n",
    "    model.Params.LazyConstraints = 1    \n",
    "    model.Params.Threads =  user_Threads\n",
    "    model.Params.LogToConsole = 0\n",
    "    \n",
    "    # Log file naming based on callback type\n",
    "    if callback_type == 'Separation':\n",
    "        model.setParam(\"LogFile\", f\"Log_ZR_{filename}\")            \n",
    "    elif callback_type == 'BRD_Separation':\n",
    "        model.setParam(\"LogFile\", f\"Log_BZR_{filename}\")            \n",
    "        \n",
    "    # Update time limit to account for setup time\n",
    "    remaining_time = time_limit - (time.time() - start_time)\n",
    "    model.setParam('TimeLimit',remaining_time)\n",
    "    \n",
    "    # Launch solver with appropriate callback\n",
    "    if callback_type == 'Separation':\n",
    "        model.optimize(Separation)\n",
    "    elif callback_type == 'BRD_Separation':\n",
    "        model.optimize(BRD_Separation)\n",
    "\n",
    "    runtime=model.Runtime\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    # === Extract final solution ===\n",
    "    best_response_items = {player: [] for player in players}\n",
    "    printSolution(model,x, best_response_items)\n",
    "    \n",
    "    return model, elapsed_time, best_response_items, first_PNE_obj, first_time, [len(EI_cuts), len(EI_D_cuts), len(EI_P_cuts), len(PNE_cuts)], PNE_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37cf08e-15a7-45c5-94d8-f95a9390147d",
   "metadata": {},
   "source": [
    "## Experiment Loop: Run All Settings for KPG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fc3dc9-0656-4c12-8bf4-affc7f22cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_set = ['A', 'B', 'C']\n",
    "standard_time_limit = 1800\n",
    "user_Threads = 16\n",
    "\n",
    "for category in category_set:\n",
    "    directory_path = f\"{my_folder}/BRP_ZR_KPG_100/KPG_generated/type_{category}\"\n",
    "    filenames = os.listdir(directory_path)\n",
    "\n",
    "    for filename in filenames:\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"Processing file: {filename}\")\n",
    "\n",
    "        # === Load Instance File ===\n",
    "        with open(os.path.join(directory_path, filename), 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        chars = filename.split('-')  # Used for filename parsing\n",
    "\n",
    "        # === Parse Game Parameters ===\n",
    "        num_players, num_items = map(int, lines[0].split())\n",
    "        items = list(range(num_items))\n",
    "        players = list(range(num_players))\n",
    "        players_complement = {player: [p for p in players if p != player] for player in players}\n",
    "        budgets = list(map(float, lines[1].split()))\n",
    "\n",
    "        # === Initialize Profits, Weights, and Interactions ===\n",
    "        profits = {player: {} for player in players}\n",
    "        weights = {player: {} for player in players}\n",
    "        players_interaction = list(permutations(players, 2))\n",
    "        interactions = {action: {} for action in players_interaction}\n",
    "\n",
    "        for line in lines[2:]:\n",
    "            data = list(map(int, line.split()))\n",
    "            item = data[0]\n",
    "\n",
    "            for player in players:\n",
    "                profits[player][item] = data[2 * player + 1]\n",
    "                weights[player][item] = data[2 * player + 2]\n",
    "\n",
    "            offset = 2 * len(players) + 1\n",
    "            for idx, action in enumerate(players_interaction):\n",
    "                interactions[action][item] = data[offset + idx]\n",
    "\n",
    "        # === Run OSW (Centralized Welfare Maximization) ===\n",
    "        print(\"=\" * 35 + \"  SW_model  \" + \"=\" * 35)\n",
    "        OSW, time_OSW, OSW_selected_items = SW_model(standard_time_limit, 'OSW')\n",
    "        selfish_obj_OSW, global_obj_OSW = from_x_to_obj(OSW_selected_items)\n",
    "        print('global obj: ',global_obj_OSW)\n",
    "\n",
    "        # === Run BRD (initial strategy profile: 0) === #\n",
    "        print(\"=\" * 35 + \"  BRD(0)_model  \" + \"=\" * 35)\n",
    "        x_current = {player: [] for player in players}\n",
    "        start_time = time.time()\n",
    "        first_PNE, PNE_found_BRD_0,  Cycle_found_BRD_0, iterations_BRD_0, obj  = BRD(x_current, None, max_init=10, max_iteration=20)\n",
    "        end_time = time.time()\n",
    "        time_BRD_0 = end_time - start_time\n",
    "        selfish_obj_BRD_0, global_obj_BRD_0 = from_x_to_obj(first_PNE)\n",
    "        print('global obj: ',global_obj_BRD_0)\n",
    "        \n",
    "        # === Run BRD (initial strategy profile: time-limited OSW solution) === #\n",
    "        print(\"=\" * 35 + \"  BRD(OSW)_model  \" + \"=\" * 35)\n",
    "        OSWW, time_OSWW, OSWW_selected_items = SW_model(standard_time_limit, 'OSW_warm')\n",
    "        start_time = time.time()\n",
    "        near_best_PNE, PNE_found_BRD_OSW, Cycle_found_BRD_OSW, iterations_BRD_OSW, obj  = BRD(OSWW_selected_items, None, max_init=10, max_iteration=20)\n",
    "        end_time = time.time()\n",
    "        time_BRD_OSW = end_time - start_time + time_OSWW\n",
    "        selfish_obj_BRD_OSW, global_obj_BRD_OSW = from_x_to_obj(near_best_PNE)\n",
    "        print('global obj: ',global_obj_BRD_OSW)\n",
    "\n",
    "        # === Run ZR with Basic Separation Oracle === #\n",
    "        print(\"=\" * 35 + \"  ZR_model  \" + \"=\" * 35)\n",
    "        model_ZR, time_ZR, best_PNE_ZR, global_obj_first_ZR, first_time_ZR, num_cuts_ZR, PNE_sets_ZR = ZR(standard_time_limit, None, category, 'Separation')\n",
    "        selfish_obj_ZR, global_obj_ZR = from_x_to_obj(best_PNE_ZR)\n",
    "\n",
    "        # === Run ZR with CR-BRD Enhanced Separation (BZR) === #\n",
    "        print(\"=\" * 35 + \"  BZR_model  \" + \"=\" * 35)\n",
    "        model_BZR, time_BZR, best_PNE_BZR, global_obj_first_BZR, first_time_BZR, num_cuts_BZR, PNE_sets_BZR = ZR(standard_time_limit, None, category, 'BRD_Separation')\n",
    "        selfish_obj_BZR, global_obj_BZR = from_x_to_obj(best_PNE_BZR)\n",
    "\n",
    "        ##################################  Summarize Results ####################################\n",
    "\n",
    "        # Create a DataFrame with specified indexes and columns\n",
    "        indexes1 = ['Total']\n",
    "    \n",
    "        # Create a DataFrame with specified indexes and columns\n",
    "        columns = ['filename','players','items','budgets','category',\n",
    "                   'BRD(0)','BRD(OSW)','ZR_1st','ZR','BZR_1st','BZR','OSW',\n",
    "                   'Cuts_ZR', 'Cuts_BZR','PNE_Cuts_BZR', \n",
    "                   'BRD(0)_T','BRD(OSW)_T','ZR_1st_T','ZR_T','BZR_1st_T','BZR_T',\n",
    "                   'it_BRD(0)', 'it_BRD(OSW)', 'Cycle_BRD(0)', 'Cycle_BRD(OSW)',\n",
    "                   'num_PNEs_ZR','num_PNEs_BZR','bound_ZR','bound_BZR']    \n",
    "    \n",
    "        df_tmp_test = pd.DataFrame(index=indexes1, columns=columns)\n",
    "        \n",
    "        df_tmp_test.loc['Total','filename'] = filename\n",
    "        df_tmp_test.loc['Total','players'] = chars[0]\n",
    "        df_tmp_test.loc['Total','items'] = chars[1]\n",
    "        df_tmp_test.loc['Total','budgets'] = chars[2]\n",
    "        df_tmp_test.loc['Total','category'] = category\n",
    "        df_tmp_test.loc['Total','ZR_1st'] = global_obj_first_ZR\n",
    "        df_tmp_test.loc['Total','ZR'] = global_obj_ZR\n",
    "        df_tmp_test.loc['Total','BZR_1st'] = global_obj_first_BZR\n",
    "        df_tmp_test.loc['Total','BZR'] = global_obj_BZR\n",
    "        df_tmp_test.loc['Total','bound_ZR'] = str(model_ZR.ObjBound)\n",
    "        df_tmp_test.loc['Total','bound_BZR'] = str(model_BZR.ObjBound)\n",
    "        df_tmp_test.loc['Total','OSW'] = global_obj_OSW\n",
    "        df_tmp_test.loc['Total','ZR_1st_T'] = first_time_ZR\n",
    "        df_tmp_test.loc['Total','ZR_T'] = time_ZR\n",
    "        df_tmp_test.loc['Total','BZR_1st_T'] = first_time_BZR\n",
    "        df_tmp_test.loc['Total','BZR_T'] = time_BZR\n",
    "        df_tmp_test.loc['Total','Cuts_ZR'] = num_cuts_ZR[0]+num_cuts_ZR[1]+num_cuts_ZR[2]\n",
    "        df_tmp_test.loc['Total','Cuts_BZR'] = num_cuts_BZR[0]+num_cuts_BZR[1]+num_cuts_BZR[2]\n",
    "        df_tmp_test.loc['Total','PNE_Cuts_BZR'] = num_cuts_BZR[3]\n",
    "        df_tmp_test.loc['Total','num_PNEs_ZR'] = len(PNE_sets_ZR)\n",
    "        df_tmp_test.loc['Total','num_PNEs_BZR'] = len(PNE_sets_BZR)\n",
    "        df_tmp_test.loc['Total','Status_ZR'] = str(model_ZR.Status)\n",
    "        df_tmp_test.loc['Total','Status_BZR'] = str(model_BZR.Status)\n",
    "        \n",
    "        df_tmp_test.loc['Total','BRD(0)'] = global_obj_BRD_0\n",
    "        df_tmp_test.loc['Total','BRD(OSW)'] = global_obj_BRD_OSW\n",
    "        df_tmp_test.loc['Total','BRD(0)_T'] = time_BRD_0\n",
    "        df_tmp_test.loc['Total','BRD(OSW)_T'] = time_BRD_OSW\n",
    "        df_tmp_test.loc['Total','it_BRD(0)'] = iterations_BRD_0\n",
    "        df_tmp_test.loc['Total','it_BRD(OSW)'] = iterations_BRD_OSW\n",
    "        df_tmp_test.loc['Total','Cycle_BRD(0)'] = Cycle_found_BRD_0\n",
    "        df_tmp_test.loc['Total','Cycle_BRD(OSW)'] = Cycle_found_BRD_OSW\n",
    "                     \n",
    "        # === Save Results to CSV === #\n",
    "        results_path = f\"{my_folder}/BZR_KPG/KPG_results/KPG_test_{category}.csv\"\n",
    "        try:\n",
    "            df_test = pd.read_csv(results_path, index_col=0)\n",
    "            df_test = pd.concat([df_test, df_tmp_test])\n",
    "        except FileNotFoundError:\n",
    "            df_test = df_tmp_test\n",
    "    \n",
    "        df_test.to_csv(results_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1e56a-1c7e-4426-9fbf-3e3dd16253ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
